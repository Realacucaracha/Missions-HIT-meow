{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a121ed71-a872-4464-a8de-690eb44df7a8",
   "metadata": {},
   "source": [
    "## Homework #1: Prove the Gradients of the Sigmoid and Tanh Functions\n",
    "\n",
    "In this exercise, you are tasked with deriving the gradients of two common activation functions in deep learning: the sigmoid function and the tanh function. Prove each gradient and simplify your answers as much as possible.\n",
    "\n",
    "### 1. Sigmoid Function Gradient\n",
    "\n",
    "The sigmoid function is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "#### Task\n",
    "1. Differentiate $\\sigma(x)$ with respect to $x$.\n",
    "2. Show that the derivative of $\\sigma(x)$ can be expressed in terms of $\\sigma(x)$ itself:\n",
    "   \n",
    "   $$\n",
    "   \\frac{d\\sigma(x)}{dx} = \\sigma(x)(1 - \\sigma(x))\n",
    "   $$\n",
    "\n",
    "**Hint:** To simplify your work, start by applying the chain rule to the expression $\\sigma(x) = \\left(1 + e^{-x}\\right)^{-1}$.\n",
    "\n",
    "### 2. Tanh Function Gradient\n",
    "\n",
    "The hyperbolic tangent function is defined as:\n",
    "\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "#### Task\n",
    "1. Differentiate $\\tanh(x)$ with respect to $x$.\n",
    "2. Show that the derivative of $\\tanh(x)$ can be expressed as:\n",
    "\n",
    "   $$\n",
    "   \\frac{d\\tanh(x)}{dx} = 1 - \\tanh(x)^2\n",
    "   $$\n",
    "\n",
    "**Hint:** You may want to express $\\tanh(x)$ in terms of $\\sigma(x)$, noting that $\\tanh(x) = 2\\sigma(2x) - 1$, as an alternative approach.\n",
    "\n",
    "### Submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64063be",
   "metadata": {},
   "source": [
    "# ${\\color{pink}\\mathbb{Answer}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa63573",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\\\\ -->\n",
    "\\\\\n",
    "\\sigma'(x) = \\frac{-(-e^{-x})}{(1+e^{-x})^2} = \\frac{1}{1 + e^{-x}} \\cdot \\frac{e^{-x}}{1 + e^{-x}} = \\sigma(x) \\cdot \\frac{e^{-x}}{1 + e^{-x}} \\\\\n",
    "\\\\\n",
    "= \\sigma(x) \\cdot \\frac{e^{-x}+1-1}{1 + e^{-x}} = \\sigma(x) \\cdot [\\frac{e^{-x}+1}{1 + e^{-x}} +  \\frac{-1}{1 + e^{-x}}] =  \\sigma(x)(1 - \\sigma(x)) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cce4c0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\\\\ ->\n",
    "\\\\\n",
    "\\tanh'(x) = \\frac{(e^x + e^{-x})(e^x + e^{-x})-(e^x - e^{-x})(e^x - e^{-x})}{(e^x + e^{-x})^2} = \\frac{(e^x + e^{-x})^2-(e^x - e^{-x})^2}{(e^x + e^{-x})^2}\n",
    "\\\\\n",
    "=\\frac{(e^x + e^{-x})^2}{(e^x + e^{-x})^2} - \\frac{(e^x - e^{-x})^2}{(e^x + e^{-x})^2} = 1 - \\tanh(x)^2\n",
    "\n",
    "\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
