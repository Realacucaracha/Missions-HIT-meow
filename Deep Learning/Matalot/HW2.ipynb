{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f19443-dcc5-483e-ad2c-800081f5db16",
   "metadata": {},
   "source": [
    "# Homework #2: Simple Neural Network Implementation using Numpy\n",
    "\n",
    "Today we will build a simple neural network from scratch in Python using only the numpy library. We will follow the instructions from the following lin https://iamtrask.github.io/2015/07/12/basic-python-network/k:\n",
    "Basic Python Network\n",
    "(Note: The code in the website is written in Python 2, and not Pytho, try writing the code yourself before reverting to the online examplen \n",
    "#1: Import Librarit numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fb5c4-4f4e-41d5-adc9-95f97bb7950a",
   "metadata": {},
   "source": [
    "### Define the Sigmoid Function and its Derivative\n",
    "- Construct a function returning a sigmoid function:\n",
    "$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "- Construct a function returning the derivative of a sigmoid function:\n",
    "$ \\frac{d\\sigma(x)}{dx} = \\sigma(x)(1 - \\sigma(x)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08594d28-1968-4ce6-bac7-4f42bed6ab41",
   "metadata": {},
   "source": [
    "### Initialize Weights\n",
    "Build an array of three weights (3x1 array – think why these dimensions!) and initialize their value randomly. (It is good practice to use weights with normal distribution of $ \\mu = 0 $ and  $ \\sigma = \\frac{1}{3}  $ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47ab35-6fe8-4fe2-bdda-85d970e810e3",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n",
    "Create a loop, iterating 1000 times (equal to the desired number of learning steps). For each iteration, calculate the difference between the network prediction and the real value of y. Multiply that difference with the sigmoid derivative and use the dot product of this number with the input layer to update your weights for the next iteration.\n",
    "- Input and Output Data Sets\n",
    "``` python\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])on. \t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01686dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#------------------\n",
    "def sigmo(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmo_der(x):\n",
    "    return sigmo(x)*(1-sigmo(x))\n",
    "#------------------------\n",
    "learning_rat = 0.1\n",
    "bias = np.array([[0.2],[0.2],[0.2],[0.2]])      #for now we will have 4 biases all startinng at 0.2... 1 for each row in X\n",
    "weights = np.zeros((3,1))\n",
    "for i in range(3):\n",
    "    weights[i][0] = np.random.normal(0,0.333) #mean=0, std = 1/3\n",
    "#-------------------\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "y_real = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf5109",
   "metadata": {},
   "source": [
    "# ${\\color{pink}{BackPropagation}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ef8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Error: [1.06125332]\n",
      "--------Finished--------\n",
      "Final weights:\n",
      " [[ 2.48591057]\n",
      " [-0.25976312]\n",
      " [-0.96080263]] \n",
      "Erorr -> [0.01369844]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_predict = np.zeros((4,1))\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    #forward culculation:\n",
    "    for q in range(len(X)):                                           #4 times\n",
    "        y_predict[q] = sigmo( np.dot(X[q],weights) + bias[q] )        #w is 3x1 so that we can matrix multiply the X (4x3)*(3x1)\n",
    "  \n",
    "\n",
    "    #diffrence culc...(aka error)\n",
    "    Ero = 0\n",
    "    for w in range(len(y_predict)):                                   #4 times\n",
    "        Ero += (y_predict[w] - y_real[w])**2   #I choose this way because its simple and easy.\n",
    "\n",
    "    if i==0 :\n",
    "        print(\"First Error:\",Ero)           #just to compare.\n",
    "\n",
    "    #Backpropagation culc:\n",
    "    for q in range(len(y_predict)):\n",
    "        for i in range(len(weights)):\n",
    "\n",
    "            w_diff = (y_predict[q] - y_real[q]) * y_predict[q] *(1 - y_predict[q]) * X[q][i]\n",
    "            weights[i] = weights[i] - learning_rat*w_diff\n",
    "\n",
    "        bias_diff = (y_predict[q] - y_real[q]) * y_predict[q] *(1 - y_predict[q])\n",
    "        bias[q] = bias[q] - learning_rat*bias_diff\n",
    "\n",
    "print(\"--------Finished--------\\nFinal weights:\\n\",weights,\"\\nErorr ->\",Ero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afebdbd",
   "metadata": {},
   "source": [
    "### ${\\color{pink}{Quick-Explanation:}}$\n",
    "\n",
    "forward culc -> to get our y_predict\n",
    "\n",
    "diff culc -> to have an idea of the error\n",
    "\n",
    "backpropagation -> we use the math culc showed underneath and the gradient decent method with the Error.\n",
    "\n",
    "$$\n",
    "w_{ij}^{l} = w_{ij}^{l} - \\alpha \\cdot \\frac{dE}{dw_{ij}^{l}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{j}^{l} = b_{j}^{l} - \\alpha \\cdot \\frac{dE}{db_{j}^{l}}\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e172b",
   "metadata": {},
   "source": [
    "# ${\\color{pink}{MATH}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c6700",
   "metadata": {},
   "source": [
    "### First, we are going to use this:\n",
    "$$\n",
    "{O_j}^{l} = \\sigma( \\sum w_{ij}^{l}O_{i}^{l-1} ) = \\sigma(z_j^l) \n",
    "$$\n",
    "\n",
    "$$\n",
    "z_j^l = \\sum w_{ij}^{l}{O}^{l-1} \n",
    "$$\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2} \\sum_n (O_{n}^{l}-y_n)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aeca32",
   "metadata": {},
   "source": [
    "כלל שרשרת\n",
    "$$\n",
    "\\frac{dE}{dw_{ij}^{l}} = \\frac{dE}{dO_{j}^{l}} \\frac{dO_{j}^{l}}{dw_{ij}^{l}} \\\\ \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dO_{j}^{l}}{dw_{ij}^{l}} = \\frac{dO_{j}^{l}}{dz_j^l} \\frac{dz_j^l}{dw_{ij}^{l}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dE}{dw_{ij}^{l}} = \\frac{dE}{dO_{j}^{l}} \\frac{dO_{j}^{l}}{dz_j^l} \\frac{dz_j^l}{dw_{ij}^{l}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c012d",
   "metadata": {},
   "source": [
    "simple derievation:\n",
    "$$\n",
    "\\frac{dO_{j}^{l}}{dz_j^l} = \\sigma'(z_j^l) = \\sigma(z_j^l) (1- \\sigma(z_j^l)) = O_{j}^{l} (1-O_{j}^{l}) \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dz_j^l}{dw_{ij}^{l}} = O_{j}^{l-1} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dE}{dO_{j}^{l}} = O_{k}^{l} - Y_k = \\delta_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66897b3c",
   "metadata": {},
   "source": [
    "### Finally:\n",
    "$$\n",
    "\\frac{dE}{dw_{ij}^{l}} = (O_{k}^{l} - Y_k) \\cdot  O_{j}^{l-1} \\cdot  O_{j}^{l} (1-O_{j}^{l}) \n",
    "$$\n",
    "final culc\n",
    "$$\n",
    "\\frac{dE}{dw_{ij}^{l}} = \\delta_k \\cdot  O_{j}^{l-1} \\cdot  O_{j}^{l} (1-O_{j}^{l})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eec8ad",
   "metadata": {},
   "source": [
    "same thing for the bias\n",
    "$$\n",
    "\\frac{dE}{db_j^l} = \\frac{dE}{dO_{j}^{l}} \\frac{dO_{j}^{l}}{dz_j^l} \\frac{dz_j^l}{db_j^l} ==> (\\frac{dz_j^l}{db_j^l} = 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dE}{db_j^l} = \\delta_k  \\cdot  O_{j}^{l} (1-O_{j}^{l})\n",
    "$$\n",
    "\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
